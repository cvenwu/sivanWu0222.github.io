---
title: mysql学习
author: yirufeng
pin: false
toc: true
mathjax: false
sidebar:
  - blogger
  - webinfo
  - tagcloud
  - category
categories:
  - mysql
tags:
  - 极客时间
  - mysql
date: 2021-04-02 10:38:35
summary:
---

## 安装环境

> [使用虚拟机的docker安装mysql](https://www.cnblogs.com/yy-cola/p/11226924.html)

## Mysql逻辑架构
![wEbctQ](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/wEbctQ.jpg)

如图所示我们知道，Mysql可以分为server和存储引擎两大层。
1. Server层：涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
2. 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。（不同存储引擎的表数据存取方式不同，支持的功能也不同）

### 一条查询语句的执行流程

**连接器：**负责与客户端建立连接，获取权限，维持和管理连接。连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。**在完成经典的 TCP 握手**后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。
- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。
- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。

注意：
1. 一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。
2. 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。

**分析器：**词法分析+语法分析
**优化器：**
**执行器：**
1. 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证
2. 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。（对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。）

### 长连接与其遇到的问题
**概念：**数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。
**原因：**建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。
**遇到的问题：**全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了
**解决办法：**
1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2. 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态

redo log 是 InnoDB 引擎特有的日志
问题：如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高
解决方法：为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。

优点：有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。因为即使宕机我们的记录依然保存到了我们的数据库或者没有保存到数据库也保存到了日志文件中。


Server 层也有自己的日志，称为 binlog（归档日志）。只依靠 binlog 是没有 crash-safe 能力的

这两种日志有以下三点不同。
1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

slave会从master读取binlog（二进制日志文件，我们在第一章讲到过mysql的二进制日志文件）来进行数据同步


一条修改语句的执行流程如下：![BMOVqL](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/BMOVqL.jpg)
在 InnoDB 存储引擎下，一条 update 语句在 MySQL 内部执行大概会经历下面五个步骤：
1、执行器先找引擎取 id=2 这一行数据，如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2、执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3、引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4、执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5、执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交(commit)状态，更新完成。

问题：
1. 第2步调用引擎接口将数据写到哪里？内存还是磁盘上保存的数据：内存上
2. 如果事务出错，需要回滚，回滚到了哪一步(1,2,3,4,5哪个)，回滚到了第2步，此时执行一个相反的命令(通过Undo log)

小结：
我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。

redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。

sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。

Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。


事务：
在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不 是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。

事务隔离的实现：在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新 值，通过回滚操作，都可以得到前一个状态的值。

在实现上，数据库里面会创建一个视图(一致性视图read-view)，访问的时候以视图的逻辑结果为准。在“可重复 读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要 注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行 化”隔离级别下直接用加锁的方式来避免并行访问。


长事务：
长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任 何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导 致大量占用存储空间。

在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长 事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。

除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的 时候展开。






索引：
索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。
可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。

哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。

而有序数组在等值查询和范围查询场景中的性能就都非常优秀。如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。

所以，有序数组索引只适用于静态存储引擎




在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间
为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。


这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。



根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。


基于主键索引和普通索引的查询有什么区别？

如果查不到我们要的字段，基于非主键索引的查询需要多扫描一棵索引树，称为回表。


由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。

由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。


## 事务

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。**事务在执行期间看到的数据前后必须是一致的。**
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。


Oracle 数据库的默认隔离级别其实就是“读提交”。Mysql默认隔离级别就是“可重读”


可重读应用场景：假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。**这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。**



回滚日志总不能一直保留吧，什么时候删除呢？：答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。
什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。


## 索引


索引的出现其实就是为了提高数据查询的效率，就像书的目录一样


哈希表这种结构适用于只有等值查询的场景

![7AuOfo](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/7AuOfo.png)

覆盖索引：查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引
优化手段：由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。


联合索引底层结构：索引项是按照索引定义里面出现的字段顺序排序

最左前缀原则：可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。


索引的选择：，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。

这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。

索引下推：

例如执行如下的SQL语句：`mysql> select * from tuser where name like '张 %' and age=10 and ismale=1;`
在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。
图 3 无索引下推执行流程：![eZ6WXV](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/eZ6WXV.jpg)

而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

图 4 索引下推执行流程：![CAvxIn](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/CAvxIn.jpg)

在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。

图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。

图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。

原则：在满足语句需求的情况下， **尽量少地访问资源**是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在**设计表结构（包括索引）**时，也要**以减少资源**消耗作为目标


09做的笔记：
唯一索引与普通索引区别：
对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。



InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。

当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。

但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。




总结：
回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。


change buffer与我们前面讲的redo log容易混淆：
所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。



14做的笔记：
MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这 个数，效率很高；

而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面 读出来，然后累积计数。

15做的笔记：

![juEgjC](https://cdn.jsdelivr.net/gh/sivanWu0222/ImageHosting@master/uPic/juEgjC.jpg)
Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。

总结课做的笔记：
带新人：
1. 第一步就是要求他们手动搭建一套主备复制结构。并且，平时碰到问 题的时候，我要求要动手复现
2. 有不少同学在跟着专栏中的案例做实验，我觉得这是个非 常好的习惯，希望你能继续坚持下去。在阅读其他技术文章、图书的时候，也是同样的道 理。如果你觉得自己理解了一个知识点，也一定要尝试设计一个例子来验证它。
3. 在设计案例的时候，我建议你也设计一个对照的反例，从而达到知识融汇贯通的目 的。就像我在写这个专栏的过程中，就感觉自己也涨了不少知识，主要就得益于给文章设计 案例的过程。
4. 原理说不清，双手白费劲。主动讲解自己理解的，并且进一步升华境界到写出来（把知识点“写下来”，还有一个好处，就是你会发现这个知识点的关联知识点。深究下去， 点就连成线，然后再跟别的线找交叉）
5. 手册补全面，案例扫盲点：看手册的时机，应该是你的知识 网络构建得差不多的时候。那你可能会问，什么时候算是差不多呢？其实，这没有一个固定的标准。但是，有一些基本 实践可以帮你去做一个检验。
  1. 能否解释清楚错误日志（error log）、慢查询日志（slow log）中每一行的意思？
  2. 能否快速评估出一个表结构或者一条 SQL 语句，设计得是否合理？
  3. 能否通过 explain 的结果，来“脑补”整个执行过程（我们已经在专栏中练习几次 了）？
  4. 到网络上找 MySQL 的实践建议，对于每一条做一次分析： 如果觉得不合理，能否给出自己的意见？
  5. 如果觉得合理，能否给出自己的解释？那，怎么判断自己的意见或者解释对不对呢？最快速、有效的途径，就是找有经验的人讨 论。比如说，留言到我们专栏的相关文章的评论区，就是一个可行的方法。
  这些实践做完后，你就应该对自己比较有信心了。这时候，你可以再去看手册，把知识网络 中的盲点补全，进而形成面。而补全的方法就是前两点了，理论加实践。